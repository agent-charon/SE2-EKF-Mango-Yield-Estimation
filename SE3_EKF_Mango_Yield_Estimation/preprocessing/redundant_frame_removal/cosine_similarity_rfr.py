import cv2
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity # For a robust implementation

class CosineSimilarityRFR:
    def __init__(self, similarity_threshold=0.90, downscale_factor=4):
        """
        Removes redundant frames based on cosine similarity.
        Paper: "cosine similarity technique to remove redundant frames with 90% similarity"
               "Eq. 1. These frame vectors are generated by reshaping the pixel matrices of
                each frame into a single vector."

        Args:
            similarity_threshold (float): Threshold for cosine similarity.
                                          Frames with similarity >= threshold are considered redundant.
            downscale_factor (int): Factor to downscale images before flattening.
                                    Reduces computation for large frames.
        """
        if not 0 < similarity_threshold <= 1.0:
            raise ValueError("Similarity threshold must be between 0 (exclusive) and 1 (inclusive).")
        if downscale_factor < 1:
            raise ValueError("Downscale factor must be at least 1.")

        self.similarity_threshold = similarity_threshold
        self.downscale_factor = downscale_factor
        self.last_kept_frame_vector = None
        self.kept_frames_indices = [] # Store indices of non-redundant frames
        self.processed_frame_count = 0

    def _preprocess_and_flatten(self, frame):
        """
        Downscales, converts to grayscale, and flattens a frame.
        """
        if frame is None:
            return None
        
        if self.downscale_factor > 1:
            new_width = frame.shape[1] // self.downscale_factor
            new_height = frame.shape[0] // self.downscale_factor
            if new_width == 0 or new_height == 0: # Avoid zero dimensions
                 # print(f"Warning: Downscale factor {self.downscale_factor} too large for frame size {frame.shape}. Using original size.")
                 frame_resized = frame
            else:
                frame_resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
        else:
            frame_resized = frame

        if frame_resized.ndim == 3 and frame_resized.shape[2] == 3: # Color image
            gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)
        elif frame_resized.ndim == 2: # Already grayscale
            gray_frame = frame_resized
        else:
            raise ValueError("Frame must be BGR or grayscale.")
            
        return gray_frame.flatten().astype(np.float32) # Ensure float for cosine sim

    def check_frame(self, current_frame):
        """
        Checks if the current frame is redundant compared to the last kept non-redundant frame.

        Args:
            current_frame (np.array): The current video frame (BGR).

        Returns:
            bool: True if the frame is NOT redundant (should be kept), False otherwise.
        """
        current_frame_vector = self._preprocess_and_flatten(current_frame)
        self.processed_frame_count +=1

        if current_frame_vector is None:
            return False # Cannot process, consider it redundant or skip

        if self.last_kept_frame_vector is None:
            # This is the first frame, always keep it.
            self.last_kept_frame_vector = current_frame_vector
            self.kept_frames_indices.append(self.processed_frame_count -1)
            return True

        # Calculate cosine similarity
        # sklearn's cosine_similarity expects 2D arrays (samples, features)
        similarity = cosine_similarity(self.last_kept_frame_vector.reshape(1, -1),
                                       current_frame_vector.reshape(1, -1))[0, 0]
        
        # Manual Cosine Similarity (as per paper's Eq. 1)
        # dot_product = np.dot(self.last_kept_frame_vector, current_frame_vector)
        # norm_last = np.linalg.norm(self.last_kept_frame_vector)
        # norm_current = np.linalg.norm(current_frame_vector)
        # if norm_last == 0 or norm_current == 0: # Avoid division by zero
        #     similarity = 1.0 if norm_last == norm_current else 0.0
        # else:
        #     similarity = dot_product / (norm_last * norm_current)

        if similarity < self.similarity_threshold:
            # Frame is different enough, keep it
            self.last_kept_frame_vector = current_frame_vector
            self.kept_frames_indices.append(self.processed_frame_count-1)
            return True
        else:
            # Frame is redundant
            return False

    def get_kept_frame_indices(self):
        return self.kept_frames_indices

    def reset(self):
        """Resets the state for a new video sequence."""
        self.last_kept_frame_vector = None
        self.kept_frames_indices = []
        self.processed_frame_count = 0


if __name__ == '__main__':
    # Parameters from paper
    threshold = 0.90
    rfr = CosineSimilarityRFR(similarity_threshold=threshold, downscale_factor=2)

    # Create dummy frames
    frame1 = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)
    frame2 = frame1.copy() # Identical
    frame3 = frame1.copy()
    cv2.putText(frame3, "Diff", (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2) # Slightly different
    frame4 = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8) # Very different

    frames = [frame1, frame2, frame3, frame4, frame1.copy()] # Add frame1 again

    print(f"Checking frames with similarity threshold: {threshold}")
    non_redundant_frames_count = 0
    for i, frame in enumerate(frames):
        is_non_redundant = rfr.check_frame(frame)
        if is_non_redundant:
            non_redundant_frames_count +=1
            print(f"Frame {i}: Kept (Non-redundant)")
        else:
            print(f"Frame {i}: Discarded (Redundant)")
            
    print(f"\nTotal frames processed: {len(frames)}")
    print(f"Total non-redundant frames kept: {non_redundant_frames_count}")
    print(f"Indices of kept frames: {rfr.get_kept_frame_indices()}")
    
    # Expected outcome:
    # Frame 0: Kept (first frame)
    # Frame 1: Discarded (identical to frame 0)
    # Frame 2: Kept (different from frame 0)
    # Frame 3: Kept (different from frame 2)
    # Frame 4: Discarded (similar to frame 3 if frame3 became the last_kept, or similar to frame1 if logic is subtle)
    #   Correction: RFR compares to the *last kept frame*.
    #   - Frame 0 kept. last_kept = frame0_vec
    #   - Frame 1 vs frame0_vec -> redundant.
    #   - Frame 2 vs frame0_vec -> non-redundant. last_kept = frame2_vec
    #   - Frame 3 vs frame2_vec -> non-redundant. last_kept = frame3_vec
    #   - Frame 4 (copy of frame1) vs frame3_vec -> likely non-redundant. last_kept = frame4_vec (frame1_vec)

    # Retest with corrected expectation:
    rfr.reset()
    print("\nRe-testing with corrected understanding:")
    expected_results = [True, False, True, True, True] # Expect frame4 (copy of frame1) to be kept if frame3 was sufficiently different
    
    # Simulate again:
    # F0 (A) -> Kept. LastKept = A
    # F1 (A) vs A -> Redundant. LastKept = A
    # F2 (B) vs A -> Kept. LastKept = B
    # F3 (C) vs B -> Kept. LastKept = C
    # F4 (A) vs C -> Kept. LastKept = A
    
    actual_kept_indices = []
    for i, frame in enumerate(frames):
        if rfr.check_frame(frame):
            actual_kept_indices.append(i)
    print(f"Actual kept indices: {actual_kept_indices}")
    # This depends on how different frame3 is made. If frame3 is very different from frame1,
    # then frame4 (copy of frame1) will be different from frame3 and thus kept.

    # To use in a video loop:
    # cap = cv2.VideoCapture("your_video.mp4")
    # rfr_processor = CosineSimilarityRFR(similarity_threshold=0.90)
    # non_redundant_frame_list = []
    # original_frame_indices = []
    # frame_idx = 0
    # while True:
    #     ret, frame = cap.read()
    #     if not ret: break
    #     if rfr_processor.check_frame(frame):
    #         non_redundant_frame_list.append(frame)
    #         original_frame_indices.append(frame_idx)
    #     frame_idx += 1
    # cap.release()
    # print(f"Kept {len(non_redundant_frame_list)} non-redundant frames.")
    # print(f"Original indices of kept frames: {rfr_processor.get_kept_frame_indices()}")